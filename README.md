ğŸ“Š project_dados
SimulaÃ§Ã£o local de um Data Lake com aplicaÃ§Ã£o prÃ¡tica de ETL utilizando PySpark.

ğŸ“Œ VisÃ£o Geral
Este projeto tem como objetivo simular um ambiente de Data Lake local, aplicando processos de ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga (ETL) com o uso do PySpark. A iniciativa visa consolidar conhecimentos em engenharia de dados, proporcionando uma compreensÃ£o prÃ¡tica das etapas envolvidas no processamento de grandes volumes de dados.

ğŸ§° Tecnologias Utilizadas
Python 3.x

Apache Spark com PySpark

ğŸ—‚ï¸ Estrutura do Projeto
A organizaÃ§Ã£o dos diretÃ³rios e arquivos estÃ¡ estruturada da seguinte forma:

```
project_dados/
â”œâ”€â”€ Data/                 # Dados brutos utilizados na simulaÃ§Ã£o
â”œâ”€â”€ DataLake/             # Armazenamento simulado do Data Lake
â”œâ”€â”€ script/               # Scripts principais de ETL
â”œâ”€â”€ utils.py              # FunÃ§Ãµes auxiliares para o processo
â””â”€â”€ README.md             # DocumentaÃ§Ã£o do projeto
```


âš™ï¸ Funcionalidades
SimulaÃ§Ã£o de um ambiente de Data Lake local

Processos de ETL utilizando PySpark

TransformaÃ§Ãµes e limpezas de dados

Armazenamento dos dados processados no Data Lake simulado

ğŸš€ Como Executar
Clone o repositÃ³rio:
```
git clone https://github.com/denilsonss/project_dados.git

cd project_dados

Crie e ative um ambiente virtual (opcional, mas recomendado):
```
```
python -m venv venv

source venv/bin/activate  # Para Linux/Mac

venv\Scripts\activate     # Para Windows

```
Instale as dependÃªncias:

```
pip install -r requirements.txt
```
Nota: Certifique-se de que o Apache Spark esteja corretamente configurado em seu ambiente.

ğŸ§ª Exemplos de Uso
Para visualizar o processo de ETL em aÃ§Ã£o, vocÃª pode executar os notebooks disponÃ­veis na pasta script/. Eles demonstram passo a passo a extraÃ§Ã£o, transformaÃ§Ã£o e carga dos dados no Data Lake simulado.

ğŸ“ˆ Resultados Esperados
ApÃ³s a execuÃ§Ã£o dos scripts, os dados processados estarÃ£o disponÃ­veis na pasta DataLake/, prontos para anÃ¡lises posteriores ou integraÃ§Ãµes com outras ferramentas de Business Intelligence.

ğŸ¤ ContribuiÃ§Ãµes
ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou pull requests com sugestÃµes de melhorias, correÃ§Ãµes ou novas funcionalidades.
GitHub
